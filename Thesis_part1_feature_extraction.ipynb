{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lvwen8H1K1t6",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install scikit-image==0.19.3\n",
        "!pip install pandas openpyxl\n",
        "!pip install pyradiomics\n",
        "!pip install mahotas\n",
        "!pip install thefuzz[speedup]\n",
        "!pip install scikit-learn opencv-python\n",
        "!pip install numpy==1.23.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njsQKegtK3pi"
      },
      "outputs": [],
      "source": [
        "# Import standard libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import shutil\n",
        "import warnings\n",
        "\n",
        "# Image processing libraries\n",
        "from skimage import io, color, img_as_ubyte, filters\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import gabor\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "from skimage.filters.rank import median\n",
        "from skimage.morphology import disk, remove_small_objects, closing\n",
        "from skimage.segmentation import chan_vese\n",
        "from skimage.measure import regionprops, moments_central, label\n",
        "\n",
        "# Statistical analysis libraries\n",
        "from scipy.stats import f_oneway\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "\n",
        "# Machine learning and dimensionality reduction\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
        "\n",
        "# Texture analysis libraries\n",
        "import mahotas\n",
        "\n",
        "!pip install SimpleITK\n",
        "!pip install pyradiomics\n",
        "\n",
        "# Radiomics libraries\n",
        "import SimpleITK as sitk\n",
        "from radiomics import featureextractor\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Upload files\n",
        "from google.colab import files\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5W0g9dwG_p28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHJkgF3iLBIN"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(img, depth=3.5):\n",
        "\n",
        "    # Crop the image\n",
        "    cropped_image = img\n",
        "\n",
        "    # Resize the image to have height 500 pixels, maintaining aspect ratio\n",
        "    h, w = cropped_image.shape[:2]\n",
        "    new_h = 500\n",
        "    new_w = int((new_h / h) * w)\n",
        "    resized_img = cv2.resize(cropped_image, (new_w, new_h))\n",
        "\n",
        "    # Compute mean luminance of the original image\n",
        "    if len(resized_img.shape) == 3:\n",
        "        gray_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray_img = resized_img\n",
        "\n",
        "    mean_luminance_original = np.mean(gray_img)\n",
        "\n",
        "    # Denoise using rank order filter (approximated using median filter)\n",
        "    denoised_img = median(gray_img, disk(1))\n",
        "\n",
        "    # Varying Clip Limit CLAHE\n",
        "    tile_grid_size = (8, 8)\n",
        "    clip_limit = 0.01\n",
        "\n",
        "    # Adjust clip limit ratio based on mean luminance\n",
        "    if mean_luminance_original < 80:\n",
        "        clip_limit_ratio = 1.35  # Adjust as needed\n",
        "    elif mean_luminance_original > 80:\n",
        "        clip_limit_ratio = 1.05  # Adjust as needed\n",
        "    else:\n",
        "        clip_limit_ratio = 1.0\n",
        "\n",
        "    initial_clip_limit_ratio = 1.0\n",
        "    best_clip_limit = clip_limit\n",
        "\n",
        "    # Apply CLAHE with varying clip limits\n",
        "    while initial_clip_limit_ratio < clip_limit_ratio:\n",
        "        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
        "        clahe_img = clahe.apply(denoised_img)\n",
        "        mean_luminance_clahe = np.mean(clahe_img)\n",
        "        initial_clip_limit_ratio = mean_luminance_clahe / mean_luminance_original\n",
        "        clip_limit += 0.001\n",
        "        if clip_limit > 10:\n",
        "            break  # Prevent infinite loop\n",
        "\n",
        "    best_clip_limit = clip_limit\n",
        "\n",
        "    # Apply CLAHE with the best clip limit\n",
        "    clahe = cv2.createCLAHE(clipLimit=best_clip_limit, tileGridSize=tile_grid_size)\n",
        "    clahe_img = clahe.apply(denoised_img)\n",
        "\n",
        "    # Varying gamma\n",
        "    min_ratio = 0.56  # Adjust as needed\n",
        "    initial_gamma = 1.0\n",
        "    ratio = 1.0\n",
        "\n",
        "    while ratio > min_ratio:\n",
        "        gamma_corrected = np.power(clahe_img / 255.0, initial_gamma) * 255.0\n",
        "        gamma_corrected = np.clip(gamma_corrected, 0, 255).astype(np.uint8)\n",
        "        mean_luminance_gamma = np.mean(gamma_corrected)\n",
        "        ratio = mean_luminance_gamma / mean_luminance_original\n",
        "        initial_gamma += 0.001\n",
        "        if initial_gamma > 5:\n",
        "            break  # Prevent infinite loop\n",
        "\n",
        "    # Final gamma correction\n",
        "    gamma_corrected_img = np.power(clahe_img / 255.0, initial_gamma) * 255.0\n",
        "    gamma_corrected_img = np.clip(gamma_corrected_img, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Create a three-channel grayscale image\n",
        "    preprocessed_img = cv2.merge([gamma_corrected_img]*3)\n",
        "\n",
        "    # K-means clustering\n",
        "    double_image = preprocessed_img.astype(np.float64) / 255.0\n",
        "\n",
        "    # Reshape the image into a 2D array for k-means\n",
        "    reshaped_image = double_image.reshape(-1, 3)\n",
        "\n",
        "    # Normalize the image data using RobustScaler\n",
        "    scaler = RobustScaler()\n",
        "    reshaped_image = scaler.fit_transform(reshaped_image)\n",
        "\n",
        "    # Apply k-means clustering with k=2\n",
        "    kmeans = KMeans(n_clusters=2, random_state=0).fit(reshaped_image)\n",
        "    idx = kmeans.labels_\n",
        "\n",
        "    # Reshape the clustered image back to its original size\n",
        "    clustered_image = idx.reshape(preprocessed_img.shape[0], preprocessed_img.shape[1])\n",
        "\n",
        "    # Segmentation using Chan-Vese method\n",
        "    img_float = clustered_image.astype(np.float64)\n",
        "\n",
        "    # Initial mask for active contour\n",
        "    mask = np.zeros_like(img_float)\n",
        "    mask[25:-25, 25:-25] = 1  # Define an initial mask\n",
        "\n",
        "    # Run the active contour model (Snake) with 'Chan-Vese' method\n",
        "    cv_result = chan_vese(img_float, max_iter=3000, init_level_set=mask, tol=1e-3)\n",
        "\n",
        "    # Remove small areas\n",
        "    min_area = 550  # Adjust this threshold as needed\n",
        "    cv_cleaned = remove_small_objects(cv_result.astype(bool), min_size=min_area)\n",
        "\n",
        "    # Morphological Closing\n",
        "    selem = disk(5)  # Adjust the disk size based on the gap between regions\n",
        "    mask_closed = closing(cv_cleaned, selem)\n",
        "\n",
        "    # Remove small areas again\n",
        "    mask_cleaned = remove_small_objects(mask_closed.astype(bool), min_size=min_area)\n",
        "\n",
        "    # Detect lowest point\n",
        "    y_coords, x_coords = np.nonzero(mask_cleaned)\n",
        "    if len(y_coords) == 0:\n",
        "        minX, minY = None, None\n",
        "    else:\n",
        "        maxY = np.max(y_coords)\n",
        "        indices = np.where(y_coords == maxY)\n",
        "        minX = x_coords[indices][0]\n",
        "        minY = y_coords[indices][0]\n",
        "\n",
        "    print(f\"Minimum x value: {minX}\")\n",
        "    print(f\"Minimum y value: {minY}\")\n",
        "\n",
        "    return preprocessed_img  # Return the preprocessed image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwEr9-P6LMIJ"
      },
      "outputs": [],
      "source": [
        "def extract_morphological_features(image):\n",
        "    if len(image.shape) == 3:  # Convert RGB image to grayscale\n",
        "        image = color.rgb2gray(image)\n",
        "\n",
        "    # Threshold the image using Otsu's method\n",
        "    threshold = filters.threshold_otsu(image)\n",
        "    binary_image = image > threshold\n",
        "\n",
        "    # Label connected regions in the binary image\n",
        "    labeled_image = label(binary_image)\n",
        "    regions = regionprops(labeled_image)\n",
        "\n",
        "    if not regions:\n",
        "        return None  # Return None if no regions are found\n",
        "\n",
        "    # Select the largest connected region\n",
        "    largest_region = max(regions, key=lambda region: region.area)\n",
        "    region_image = largest_region.image.astype(np.float64)\n",
        "\n",
        "    # Compute central moments\n",
        "    moments = moments_central(region_image)\n",
        "\n",
        "    # Extract desired morphological features\n",
        "    features = {\n",
        "        'Area': largest_region.area,\n",
        "        'Eccentricity': largest_region.eccentricity,\n",
        "        'Perimeter': largest_region.perimeter,\n",
        "        'Centroid_X': largest_region.centroid[1],  # X-coordinate\n",
        "        'Centroid_Y': largest_region.centroid[0],  # Y-coordinate\n",
        "        'Moments': moments  # Store the entire moments matrix\n",
        "    }\n",
        "\n",
        "    return features\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_value(v):# to handle scalars in title string\n",
        "    # Check if v is a scalar.\n",
        "    if np.isscalar(v):\n",
        "        # Use pd.isna for scalar values.\n",
        "        if pd.isna(v):\n",
        "            return 'NaN'\n",
        "        # Format floats with 4 decimals.\n",
        "        elif isinstance(v, float):\n",
        "            return f\"{v:.4f}\"\n",
        "        else:\n",
        "            return str(v)\n",
        "    else:\n",
        "        # If v is not scalar (e.g. an array), convert it to a string\n",
        "        # using numpy's array2string with a chosen precision.\n",
        "        return np.array2string(np.array(v), precision=4, separator=', ')\n"
      ],
      "metadata": {
        "id": "sBvXjqV_0iPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06u3g_AkQMDD"
      },
      "outputs": [],
      "source": [
        "# Upload image and Excel file\n",
        "print(\"Please upload the Excel file with labels:\")\n",
        "legend = files.upload()  # Excel file with labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxA2Ze0lLwWn"
      },
      "outputs": [],
      "source": [
        "print(\"\\nPlease upload the images:\")\n",
        "uploaded = files.upload()  # Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHVpmiXmO5pc"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Organize images based on status from uploaded variable\n",
        "images_by_status = {}\n",
        "\n",
        "# Load the Excel legend\n",
        "legend_filename = next(iter(legend.keys()))  # Get the uploaded Excel filename\n",
        "legend_df = pd.read_excel(legend_filename, sheet_name='Sheet1')\n",
        "\n",
        "# Ensure the legend has the expected columns\n",
        "assert 'Code Number' in legend_df.columns, \"The Excel file must have a 'Code Number' column.\"\n",
        "assert 'Status' in legend_df.columns, \"The Excel file must have a 'Status' column.\"\n",
        "\n",
        "# Normalize the 'Code Number' column to strings for consistent matching\n",
        "legend_df['Code Number'] = legend_df['Code Number'].astype(str).str.strip()\n",
        "\n",
        "# Map codes to their corresponding statuses, using the last 4 digits for matching\n",
        "codes_to_status = {str(int(code))[-4:]: int(status) for code, status in zip(legend_df['Code Number'], legend_df['Status'])}\n",
        "\n",
        "# Debugging: Print all codes and their statuses\n",
        "print(\"\\nCodes and corresponding statuses from the legend (using last 4 digits):\")\n",
        "for code_suffix, status in codes_to_status.items():\n",
        "    print(f\"Code suffix: {code_suffix}, Status: {status}\")\n",
        "\n",
        "# Variables to hold images based on statuses\n",
        "status_0 = []\n",
        "status_1 = []\n",
        "status_2 = []\n",
        "status_3 = []\n",
        "\n",
        "# Categorize images by status\n",
        "for image_name, image_content in uploaded.items():\n",
        "    matched = False\n",
        "    # Extract numeric substrings from the image name\n",
        "    numeric_substrings = re.findall(r'\\d+', image_name)\n",
        "    # Process each numeric substring\n",
        "    for num_str in numeric_substrings:\n",
        "        num_suffix = str(int(num_str))[-4:]  # Convert to int to strip leading zeros, then get last 4 digits\n",
        "        if num_suffix in codes_to_status:\n",
        "            status = codes_to_status[num_suffix]\n",
        "            if status == 0:\n",
        "                status_0.append((image_name, image_content))\n",
        "            elif status == 1:\n",
        "                status_1.append((image_name, image_content))\n",
        "            elif status == 2:\n",
        "                status_2.append((image_name, image_content))\n",
        "            elif status == 3:\n",
        "                status_3.append((image_name, image_content))\n",
        "            matched = True\n",
        "            break  # Stop after the first match\n",
        "    if not matched:\n",
        "        print(f\"Image '{image_name}' did not match any code.\")\n",
        "\n",
        "# Debugging: Display the categorized images\n",
        "print(\"\\nImages categorized by status:\")\n",
        "print(f\"Status 0: {len(status_0)} images\")\n",
        "print(f\"Status 1: {len(status_1)} images\")\n",
        "print(f\"Status 2: {len(status_2)} images\")\n",
        "print(f\"Status 3: {len(status_3)} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3XZiJXaQ0BL"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import interact, widgets\n",
        "\n",
        "# Organize images based on status from uploaded variable\n",
        "images_by_status = {}\n",
        "\n",
        "# Load the Excel legend\n",
        "legend_filename = next(iter(legend.keys()))  # Get the uploaded Excel filename\n",
        "legend_df = pd.read_excel(legend_filename, sheet_name='Sheet1')\n",
        "\n",
        "# Ensure the legend has the expected columns\n",
        "assert 'Code Number' in legend_df.columns, \"The Excel file must have a 'Code Number' column.\"\n",
        "assert 'Status' in legend_df.columns, \"The Excel file must have a 'Status' column.\"\n",
        "\n",
        "# Normalize the 'Code Number' column to strings for consistent matching\n",
        "legend_df['Code Number'] = legend_df['Code Number'].astype(str).str.strip()\n",
        "\n",
        "# Map codes to their corresponding statuses, using the last 4 digits for matching\n",
        "codes_to_status = {str(int(code))[-4:]: int(status) for code, status in zip(legend_df['Code Number'], legend_df['Status'])}\n",
        "\n",
        "# Debugging: Print all codes and their statuses\n",
        "print(\"\\nCodes and corresponding statuses from the legend (using last 4 digits):\")\n",
        "for code_suffix, status in codes_to_status.items():\n",
        "    print(f\"Code suffix: {code_suffix}, Status: {status}\")\n",
        "\n",
        "# Variables to hold images based on statuses\n",
        "status_0 = []\n",
        "status_1 = []\n",
        "status_2 = []\n",
        "status_3 = []\n",
        "\n",
        "# Categorize images by status\n",
        "for image_name, image_content in uploaded.items():\n",
        "    matched = False\n",
        "    # Extract numeric substrings from the image name\n",
        "    numeric_substrings = re.findall(r'\\d+', image_name)\n",
        "    # Process each numeric substring\n",
        "    for num_str in numeric_substrings:\n",
        "        num_suffix = str(int(num_str))[-4:]  # Convert to int to strip leading zeros, then get last 4 digits\n",
        "        if num_suffix in codes_to_status:\n",
        "            status = codes_to_status[num_suffix]\n",
        "            if status == 0:\n",
        "                status_0.append((image_name, image_content))\n",
        "            elif status == 1:\n",
        "                status_1.append((image_name, image_content))\n",
        "            elif status == 2:\n",
        "                status_2.append((image_name, image_content))\n",
        "            elif status == 3:\n",
        "                status_3.append((image_name, image_content))\n",
        "            matched = True\n",
        "            break  # Stop after the first match\n",
        "    if not matched:\n",
        "        print(f\"Image '{image_name}' did not match any code.\")\n",
        "\n",
        "# Debugging: Display the categorized images\n",
        "print(\"\\nImages categorized by status:\")\n",
        "print(f\"Status 0: {len(status_0)} images\")\n",
        "print(f\"Status 1: {len(status_1)} images\")\n",
        "print(f\"Status 2: {len(status_2)} images\")\n",
        "print(f\"Status 3: {len(status_3)} images\")\n",
        "\n",
        "# Display images using a slider\n",
        "def display_image(status_list, idx):\n",
        "    if idx < 0 or idx >= len(status_list):\n",
        "        print(\"Invalid index\")\n",
        "        return\n",
        "    image_name, image_content = status_list[idx]\n",
        "    print(f\"Image Name: {image_name}\")\n",
        "    image_array = np.frombuffer(image_content, dtype=np.uint8)\n",
        "    img = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
        "    if img is not None:\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"Filename: {image_name}\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"Unable to decode image: {image_name}\")\n",
        "\n",
        "# Interactive sliders for each status\n",
        "def create_slider(status_list, status_label):\n",
        "    if len(status_list) == 0:\n",
        "        print(f\"No images to display for Status {status_label}.\")\n",
        "        return\n",
        "    print(f\"\\nInteractive slider for Status {status_label}:\")\n",
        "    interact(lambda idx: display_image(status_list, idx), idx=widgets.IntSlider(min=0, max=len(status_list)-1, step=1, description=f\"Status {status_label}\"))\n",
        "\n",
        "# Create sliders for each status list\n",
        "create_slider(status_0, 0)\n",
        "create_slider(status_1, 1)\n",
        "create_slider(status_2, 2)\n",
        "create_slider(status_3, 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhy4WkfOQKVH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import SimpleITK as sitk\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "from radiomics import featureextractor\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis\n",
        "from skimage.measure import moments, moments_central, moments_normalized, moments_hu\n",
        "\n",
        "# Initialize variables for storing categorized image content\n",
        "status_images = {0: [], 1: [], 2: [], 3: []}\n",
        "status_filenames = {0: [], 1: [], 2: [], 3: []}\n",
        "\n",
        "# Ensure 'legend' contains the Excel data\n",
        "if 'legend' not in locals():\n",
        "    raise ValueError(\"The 'legend' variable must be loaded with the Excel data.\")\n",
        "\n",
        "try:\n",
        "    # Get the uploaded Excel filename from the 'legend' dictionary\n",
        "    legend_filename = next(iter(legend.keys()))\n",
        "\n",
        "    # Read the Excel file into a DataFrame\n",
        "    legend_df = pd.read_excel(legend_filename, sheet_name='Sheet1')\n",
        "\n",
        "    # Ensure 'Code Number' is a string and strip whitespace\n",
        "    legend_df['Code Number'] = legend_df['Code Number'].astype(str).str.strip()\n",
        "\n",
        "    # Extract the first 6 digits from 'Code Number' to create a mapping\n",
        "    legend_df['Code_Number_6digits'] = legend_df['Code Number'].apply(\n",
        "        lambda x: re.search(r'\\b(\\d{6})\\b', x).group(1) if re.search(r'\\b(\\d{6})\\b', x) else None)\n",
        "\n",
        "    # Create a mapping from code numbers to their features\n",
        "    code_number_to_features = legend_df.set_index('Code_Number_6digits').to_dict(orient='index')\n",
        "\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Error processing 'legend' variable: {e}\")\n",
        "\n",
        "# Function to extract the first 6-digit code number from filename\n",
        "def extract_code_number(filename):\n",
        "    filename_no_ext = os.path.splitext(filename)[0]\n",
        "    match = re.search(r'\\b(\\d{6})\\b', filename_no_ext)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "# Categorize images by status\n",
        "if 'uploaded' in locals():\n",
        "    for image_name, image_content in uploaded.items():\n",
        "        extracted_code_number = extract_code_number(image_name)\n",
        "\n",
        "        if extracted_code_number and extracted_code_number in code_number_to_features:\n",
        "            status = code_number_to_features[extracted_code_number].get('Status', None)\n",
        "\n",
        "            if status in status_images:\n",
        "                status_images[status].append(image_content)\n",
        "                status_filenames[status].append(image_name)\n",
        "        else:\n",
        "            print(f\"Image '{image_name}' did not match any code.\")\n",
        "\n",
        "# Combine all status variables into a dictionary for dynamic processing\n",
        "results = []\n",
        "\n",
        "# Process images by their status\n",
        "for status, image_list in status_images.items():\n",
        "    for idx, image_content in enumerate(image_list):\n",
        "        original_filename = status_filenames[status][idx]\n",
        "\n",
        "        # Read the image from the content\n",
        "        image_array = np.frombuffer(image_content, dtype=np.uint8)\n",
        "        img = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
        "\n",
        "        if img is not None:\n",
        "            # Preprocess the image\n",
        "            img_prep = preprocess_image(img)\n",
        "\n",
        "            # Convert to grayscale\n",
        "            img_gray = cv2.cvtColor(img_prep, cv2.COLOR_BGR2GRAY) if img_prep.ndim == 3 else img_prep.copy()\n",
        "\n",
        "            # Convert the image to uint8 format\n",
        "            img_uint8 = img_gray.astype(np.uint8)\n",
        "            img_uint8 = cv2.normalize(img_uint8, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "            # Convert the NumPy image to SimpleITK image\n",
        "            sitk_image = sitk.GetImageFromArray(img_uint8)\n",
        "\n",
        "            # Create a mask with ones (foreground)\n",
        "            mask = np.ones(img_uint8.shape, dtype=np.uint8)\n",
        "            mask[0, :] = mask[-1, :] = mask[:, 0] = mask[:, -1] = 0\n",
        "            sitk_mask = sitk.GetImageFromArray(mask)\n",
        "\n",
        "            # Extract additional features from column \"C\" onwards for the matching code number\n",
        "            matching_code_number = extract_code_number(original_filename)  # Use the provided function to extract code number\n",
        "            additional_features = {}\n",
        "\n",
        "            # Check if the code number exists in the legend\n",
        "            if matching_code_number in legend_df['Code Number'].astype(str).values:\n",
        "                # Extract the row matching the code number\n",
        "                matching_row = legend_df.loc[legend_df['Code Number'].astype(str) == matching_code_number]\n",
        "\n",
        "                # Extract columns from \"C\" (index 2 in 0-based indexing) onwards\n",
        "                for col in legend_df.columns[2:]:\n",
        "                    additional_features[col] = matching_row[col].values[0]  # Extract the value\n",
        "\n",
        "            # Extract GLCM features\n",
        "            try:\n",
        "                distances = [1]\n",
        "                angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
        "                glcm = graycomatrix(img_uint8, distances=distances, angles=angles, symmetric=True, normed=True)\n",
        "\n",
        "                # Dissimilarity for each angle\n",
        "                diss_sim_0   = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
        "                diss_sim_45  = graycoprops(glcm, 'dissimilarity')[0, 1]\n",
        "                diss_sim_90  = graycoprops(glcm, 'dissimilarity')[0, 2]\n",
        "                diss_sim_135 = graycoprops(glcm, 'dissimilarity')[0, 3]\n",
        "\n",
        "                # Correlation for each angle\n",
        "                corr_0   = graycoprops(glcm, 'correlation')[0, 0]\n",
        "                corr_45  = graycoprops(glcm, 'correlation')[0, 1]\n",
        "                corr_90  = graycoprops(glcm, 'correlation')[0, 2]\n",
        "                corr_135 = graycoprops(glcm, 'correlation')[0, 3]\n",
        "\n",
        "                # Homogeneity for each angle\n",
        "                homogen_0   = graycoprops(glcm, 'homogeneity')[0, 0]\n",
        "                homogen_45  = graycoprops(glcm, 'homogeneity')[0, 1]\n",
        "                homogen_90  = graycoprops(glcm, 'homogeneity')[0, 2]\n",
        "                homogen_135 = graycoprops(glcm, 'homogeneity')[0, 3]\n",
        "\n",
        "                # Energy for each angle\n",
        "                energy_0   = graycoprops(glcm, 'energy')[0, 0]\n",
        "                energy_45  = graycoprops(glcm, 'energy')[0, 1]\n",
        "                energy_90  = graycoprops(glcm, 'energy')[0, 2]\n",
        "                energy_135 = graycoprops(glcm, 'energy')[0, 3]\n",
        "\n",
        "                # Contrast for each angle\n",
        "                contrast_0   = graycoprops(glcm, 'contrast')[0, 0]\n",
        "                contrast_45  = graycoprops(glcm, 'contrast')[0, 1]\n",
        "                contrast_90  = graycoprops(glcm, 'contrast')[0, 2]\n",
        "                contrast_135 = graycoprops(glcm, 'contrast')[0, 3]\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error computing GLCM features for '{original_filename}': {e}\")\n",
        "                diss_sim_0 = diss_sim_45 = diss_sim_90 = diss_sim_135 = np.nan\n",
        "                corr_0 = corr_45 = corr_90 = corr_135 = np.nan\n",
        "                homogen_0 = homogen_45 = homogen_90 = homogen_135 = np.nan\n",
        "                energy_0 = energy_45 = energy_90 = energy_135 = np.nan\n",
        "                contrast_0 = contrast_45 = contrast_90 = contrast_135 = np.nan\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Extract GLRLM features using PyRadiomics\n",
        "            try:\n",
        "                extractor = featureextractor.RadiomicsFeatureExtractor()\n",
        "                extractor.disableAllFeatures()\n",
        "                extractor.enableFeatureClassByName('glrlm')\n",
        "                glrlm_features = extractor.execute(sitk_image, sitk_mask)\n",
        "\n",
        "                run_length_non_uniformity = glrlm_features.get('original_glrlm_RunLengthNonUniformity', np.nan)\n",
        "                short_run_emphasis = glrlm_features.get('original_glrlm_ShortRunEmphasis', np.nan)\n",
        "                long_run_emphasis = glrlm_features.get('original_glrlm_LongRunEmphasis', np.nan)\n",
        "                gray_level_non_uniformity = glrlm_features.get('original_glrlm_GrayLevelNonUniformity', np.nan)\n",
        "                run_percentage = glrlm_features.get('original_glrlm_RunPercentage', np.nan)\n",
        "                run_entropy = glrlm_features.get('original_glrlm_RunEntropy', np.nan)\n",
        "            except Exception as e:\n",
        "                print(f\"Error computing GLRLM features for '{original_filename}': {e}\")\n",
        "                run_length_non_uniformity = short_run_emphasis = long_run_emphasis = np.nan\n",
        "                gray_level_non_uniformity = run_percentage = run_entropy = np.nan\n",
        "\n",
        "            try:\n",
        "                    # Extract morphological features\n",
        "                    morphological_features = extract_morphological_features(img_gray)\n",
        "\n",
        "                    if morphological_features:\n",
        "                        # Extract morphological features\n",
        "                        area = morphological_features['Area']\n",
        "                        eccentricity = morphological_features['Eccentricity']\n",
        "                        perimeter = morphological_features['Perimeter']\n",
        "                        centroid_x = morphological_features['Centroid_X']\n",
        "                        centroid_y = morphological_features['Centroid_Y']\n",
        "\n",
        "\n",
        "                    else:\n",
        "                        # Handle cases where no morphological features are extracted\n",
        "                        area = eccentricity = perimeter = centroid_x = centroid_y = np.nan\n",
        "\n",
        "\n",
        "            except Exception as e:\n",
        "                    # Handle exceptions gracefully and set default NaN values\n",
        "                    print(f\"Error computing morphological features for '{original_filename}': {e}\")\n",
        "                    area = eccentricity = perimeter = centroid_x = centroid_y = np.nan\n",
        "\n",
        "\n",
        "            mu = moments_central(img_gray)\n",
        "            mu00 = mu[0, 0]\n",
        "            mu01 = mu[0, 1]\n",
        "            mu02 = mu[0, 2]\n",
        "            mu10 = mu[1, 0]\n",
        "            mu11 = mu[1, 1]\n",
        "            mu12 = mu[1, 2]\n",
        "            mu20 = mu[2, 0]\n",
        "            mu21 = mu[2, 1]\n",
        "            mu22 = mu[2, 2]\n",
        "\n",
        "            nu = moments_normalized(mu)\n",
        "            nu00 = nu[0, 0]\n",
        "            nu01 = nu[0, 1]\n",
        "            nu02 = nu[0, 2]\n",
        "            nu10 = nu[1, 0]\n",
        "            nu11 = nu[1, 1]\n",
        "            nu12 = nu[1, 2]\n",
        "            nu20 = nu[2, 0]\n",
        "            nu21 = nu[2, 1]\n",
        "            nu22 = nu[2, 2]\n",
        "\n",
        "            hu = moments_hu(nu)\n",
        "            hu0 = hu[0]\n",
        "            hu1 = hu[1]\n",
        "            hu2 = hu[2]\n",
        "            hu3 = hu[3]\n",
        "            hu4 = hu[4]\n",
        "            hu5 = hu[5]\n",
        "            hu6 = hu[6]\n",
        "\n",
        "            flat_image = img_gray.flatten()\n",
        "            mean_img = np.mean(flat_image)\n",
        "            std_img = np.std(flat_image)\n",
        "            var_img = np.var(flat_image)\n",
        "            skew_img = skew(flat_image)\n",
        "            kurt_img = kurtosis(flat_image)  # Note: returns excess kurtosis\n",
        "\n",
        "\n",
        "            # Append the results to the list\n",
        "\n",
        "                        # Append the results to the list\n",
        "            result_entry = {\n",
        "                'Filename': original_filename,\n",
        "                'Status': status,\n",
        "\n",
        "                'Mean': mean_img,\n",
        "                'Std': std_img,\n",
        "                'Variance': var_img,\n",
        "                'Skewness': skew_img,\n",
        "                'Kurtosis': kurt_img,\n",
        "\n",
        "                'Dissimilarity_0': diss_sim_0,\n",
        "                'Dissimilarity_45': diss_sim_45,\n",
        "                'Dissimilarity_90': diss_sim_90,\n",
        "                'Dissimilarity_135': diss_sim_135,\n",
        "\n",
        "                'Correlation_0': corr_0,\n",
        "                'Correlation_45': corr_45,\n",
        "                'Correlation_90': corr_90,\n",
        "                'Correlation_135': corr_135,\n",
        "\n",
        "                'Homogeneity_0': homogen_0,\n",
        "                'Homogeneity_45': homogen_45,\n",
        "                'Homogeneity_90': homogen_90,\n",
        "                'Homogeneity_135': homogen_135,\n",
        "\n",
        "                'Energy_0': energy_0,\n",
        "                'Energy_45': energy_45,\n",
        "                'Energy_90': energy_90,\n",
        "                'Energy_135': energy_135,\n",
        "\n",
        "                'Contrast_0': contrast_0,\n",
        "                'Contrast_45': contrast_45,\n",
        "                'Contrast_90': contrast_90,\n",
        "                'Contrast_135': contrast_135,\n",
        "\n",
        "                'RunLengthNonUniformity': run_length_non_uniformity,\n",
        "                'ShortRunEmphasis': short_run_emphasis,\n",
        "                'LongRunEmphasis': long_run_emphasis,\n",
        "                'GrayLevelNonUniformity': gray_level_non_uniformity,\n",
        "                'RunPercentage': run_percentage,\n",
        "                'RunEntropy': run_entropy,\n",
        "\n",
        "                'Area': area,\n",
        "                'Eccentricity': eccentricity,\n",
        "                'Perimeter': perimeter,\n",
        "                'Centroid_X': centroid_x,\n",
        "                'Centroid_Y': centroid_y,\n",
        "                'Mu00': mu00, 'Mu01': mu01, 'Mu02': mu02,\n",
        "                'Mu10': mu10, 'Mu11': mu11, 'Mu12': mu12,\n",
        "                'Mu20': mu20, 'Mu21': mu21, 'Mu22': mu22,\n",
        "                # Individual normalized moments:\n",
        "                'Nu00': nu00, 'Nu01': nu01, 'Nu02': nu02,\n",
        "                'Nu10': nu10, 'Nu11': nu11, 'Nu12': nu12,\n",
        "                'Nu20': nu20, 'Nu21': nu21, 'Nu22': nu22,\n",
        "                # Hu invariant moments:\n",
        "                'Hu0': hu0, 'Hu1': hu1, 'Hu2': hu2,\n",
        "                'Hu3': hu3, 'Hu4': hu4, 'Hu5': hu5, 'Hu6': hu6\n",
        "            }\n",
        "\n",
        "             # Add the additional features to the result entry\n",
        "            result_entry.update(additional_features)\n",
        "\n",
        "\n",
        "            # Visualization\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            plt.imshow(img_gray, cmap='gray')\n",
        "            plt.axis('off')\n",
        "\n",
        "\n",
        "            # Build the title string with image features\n",
        "            'title_str = f\"Image: {original_filename}\\nStatus: {status}\"'\n",
        "            title_str = ''\n",
        "\n",
        "            for k, v in result_entry.items():\n",
        "                v_str = format_value(v)\n",
        "                title_str += f\"\\n{k}: {v_str}\"\n",
        "                title_str += f\"\\n{k}: {v_str}\"\n",
        "\n",
        "            plt.title(title_str)\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "            # Append the result entry\n",
        "            results.append(result_entry)\n",
        "        else:\n",
        "            print(f\"Failed to load image: {original_filename}\")\n",
        "\n",
        "\n",
        "# Create a DataFrame and save the results\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv('extracted_features_with_prep.csv', index=False)\n",
        "print(\"Features saved to 'extracted_features_with_prep.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEO9W4crvS_g"
      },
      "outputs": [],
      "source": [
        "files.download('extracted_features_with_prep.csv')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}